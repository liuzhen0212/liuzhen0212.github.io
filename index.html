<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Zhen Liu</title>
    <meta name="author" content="Zhen Liu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px"><td style="padding:0px">

        <!-- First Part: Brief introduction -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:72%;vertical-align:middle">
              <p class="name" style="text-align: center;">
                <b> Zhen Liu (刘振) </b>
              </p>
              <p style="text-align:justify">
                I am currently a Ph.D. student in the <a href="https://cite.nju.edu.cn/">Computational Imaging Technology & Engineering Lab</a> at Nanjing University,
                under the supervision of <a href="https://cite.nju.edu.cn/People/Faculty/20190621/i5054.html">Prof. Xun Cao</a> 
                and <a href="https://cs.nju.edu.cn/ywguo/index.htm">Prof. Yanwen Guo</a>. 
              </p>  
              <p style="text-align:justify">
                Piror to this, I received my bachelor's degree from Beijing Institute of Technology in 2021. 
                I was a Fulltime intern with Internet Graphics Group at Microsoft Research Asia from Dec. 2020 to Jun. 2021.
                I was a graduate student at Nanjing University from 2021 to 2023, and became a doctoral student in Sep. 2023.
              </p>
              <p style="text-align:center">
                <a href="mailto:zhenliu@smail.nju.edu.cn">Email</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.co.kr/citations?user=d-S9cjIAAAAJ&hl=zh-CN">Scholar</a> &nbsp;/&nbsp;
                <a href="https://github.com/liuzhen0212">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/ZhenLiu.jpg"><img style="width:100%;max-width:100%;object-fit: cover;" alt="profile photo" src="images/ZhenLiu.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- Second Part: Research introduction -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                I'm interested in <strong>Implicit Neural Representation</strong>, <strong>Neural Radiance Fields</strong> and <strong>Inverse Problem Optimization</strong>.
                <!-- Representative papers are <span class="highlight">highlighted</span>. -->
              </p>
            </td>
          </tr>
        </tbody></table>
          
        <!-- Third Part: Publications -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <!-- FINER -->
          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/Finer CVPR2024.png' width="220">
            </td>
            
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://liuzhen0212.github.io/finer"> 
                <span class="papertitle">FINER: Flexible spectral-bias tuning in Implicit NEural Representation by Variable-periodic Activation Functions</span>
              </a>
              <br>
              <strong>Zhen Liu</strong><sup>*</sup>,
              <a href="https://pakfa.github.io/zhuhao_photo.github.io/">Hao Zhu</a><sup>*</sup>,
              <a href="https://qzhang-cv.github.io/">Qi Zhang</a>,
              <a href="https://fiddiemath.github.io/">Jingde Fu</a>,
              <a href="https://math.nju.edu.cn/szdw/apypl1/20190916/i22123.html">Weibing Deng</a>,
              <a href="https://vision.nju.edu.cn/main.htm">Zhan Ma</a>,
              <a href="https://cs.nju.edu.cn/ywguo/index.htm">Yanwen Guo</a>,
              <a href="https://cite.nju.edu.cn/People/Faculty/20190621/i5054.html">Xun Cao</a>
              <br>
              <em>CVPR</em>, 2024 
              <!-- &nbsp  -->
              <!-- <font color="red"><strong>(Oral Presentation, Best Paper Finalist)</strong></font> -->
              <br>
              <a href="https://liuzhen0212.github.io/finer">Project Page</a>
              /
              <a href="https://arxiv.org/abs/2312.02434">arXiv</a>
              /
              <a href="https://github.com/liuzhen0212/FINER">Code</a>
              <!-- <p style="text-align:justify">
                We propose a novel implicit neural representation with flexible spectral-bias tuning for representing and optimizing signals.
              </p> -->
            </td>
          </tr>

          <!-- DINER (Journal) -->
          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/Diner TPAMI2024.png' width="220">
            </td>
            
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/10436706"> 
                <span class="papertitle">Disorder-invariant Implicit Neural Representation</span>
              </a>
              <br>
              <a href="https://pakfa.github.io/zhuhao_photo.github.io/">Hao Zhu</a><sup>*</sup>,
              <a href="https://github.com/Ezio77">Shaowen Xie</a><sup>*</sup>,
              <strong>Zhen Liu</strong><sup>*</sup>,
              <a href="">Fengyi Liu</a>,
              <a href="https://qzhang-cv.github.io/">Qi Zhang</a>,
              <a href="https://zhouyou-nju.github.io/">You Zhou</a>,
              <a href="">Yi Lin</a>,
              <a href="https://vision.nju.edu.cn/main.htm">Zhan Ma</a>,
              <a href="https://cite.nju.edu.cn/People/Faculty/20190621/i5054.html">Xun Cao</a>
              <br>
              <em>TPAMI</em>, 2024 
              <br>
              <a href="https://ieeexplore.ieee.org/document/10436706">Paper</a>
              /
              <a href="https://arxiv.org/abs/2304.00837">arXiv</a>
              /
              <a href="https://github.com/Ezio77/DINER">Code</a>
              <!-- <p style="text-align:justify">
                The expressive power of the DINER is determined by the width of the hash-table. Different width corresponds to different geometrical elements in the attribute space, e.g., 1D curve, 2D curved-plane and 3D curved-volume when the width is set as 1, 2 and 3, respectively. 
              </p> -->
            </td>
          </tr>

          <!-- DINER (Conference) -->
          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/Diner CVPR2023.png' width="220">
            </td>
            
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ezio77.github.io/DINER-website/"> 
                <span class="papertitle">DINER: Disorder-Invariant Implicit Neural Representation</span>
              </a>
              <br>
              <a href="https://github.com/Ezio77">Shaowen Xie</a><sup>*</sup>,
              <a href="https://pakfa.github.io/zhuhao_photo.github.io/">Hao Zhu</a><sup>*</sup>,
              <strong>Zhen Liu</strong><sup>*</sup>,
              <a href="https://qzhang-cv.github.io/">Qi Zhang</a>,
              <a href="https://zhouyou-nju.github.io/">You Zhou</a>,
              <a href="https://cite.nju.edu.cn/People/Faculty/20190621/i5054.html">Xun Cao</a>,
              <a href="https://vision.nju.edu.cn/main.htm">Zhan Ma</a>
              <br>
              <em>CVPR</em>, 2023 &nbsp;
              <font color="red"><strong>(Highlight Paper)</strong></font>
              <br>
              <a href="https://ezio77.github.io/DINER-website/">Project Page</a>
              /
              <a href="https://arxiv.org/abs/2211.07871">arXiv</a>
              /
              <a href="https://github.com/Ezio77/DINER">Code</a>
              <!-- <p style="text-align:justify">
                The inferior representation capacity of the existing INR model is largely increased by the proposed DINER, in which a hash-table is augmented to map the coordinates of the original input for better characterization in the succeeding INR model.
              </p> -->
            </td>
          </tr>


          <!-- DNF -->
          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/DNF OE2022.png' width="220">
            </td>
            
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-30-11-18168"> 
                <span class="papertitle">DNF: diffractive neural field for lensless microscopic imaging</span>
              </a>
              <br>
              <a href="https://pakfa.github.io/zhuhao_photo.github.io/">Hao Zhu</a><sup>*</sup>,
              <strong>Zhen Liu</strong><sup>*</sup>,
              <a href="https://zhouyou-nju.github.io/">You Zhou</a>,
              <a href="https://vision.nju.edu.cn/main.htm">Zhan Ma</a>,
              <a href="https://cite.nju.edu.cn/People/Faculty/20190621/i5054.html">Xun Cao</a>
              <br>
              <em>Optics Express</em>, 2022
              <br>
              <a href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-30-11-18168">Paper</a>
              /
              <a href="https://github.com/liuzhen0212/DNF">Code</a>
              <!-- <p style="text-align:justify">
                We propose a novel unsupervised Diffractive Neural Field (DNF) method to accurately characterize the imaging physical process to best reconstruct desired complex field of the target object through very limited measurement snapshots by jointly optimizing the imaging parameter and implicit mapping between spatial coordinates and complex field.
              </p> -->
            </td>
          </tr>

          <!-- VirtualCube -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/VirtualCube VR2022.png' width="220">
            </td>
            
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9714050"> 
                <span class="papertitle">VirtualCube: An Immersive 3D Video Communication System</span>
              </a>
              <br>
              <a href="">Yizhong Zhang</a><sup>*</sup>,
              <a href="https://jlyang.org/">Jiaolong Yang</a><sup>*</sup>,
              <strong>Zhen Liu</strong>,
              <a href="">Ruicheng Wang</a>,
              <a href="">Guojun Chen</a>,
              <a href="">Xin Tong</a>,
              <a href="">Baining Guo</a>
              <br>
              <em>VR (&TVCG)</em>, 2022 &nbsp;
              <font color="red"><strong>(Best Paper Award)</strong></font>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9714050">Paper</a>
              <!-- <p style="text-align:justify">
              </p> -->
            </td>
          </tr>

        </tbody></table>
      </td></tr>
    </table>
  </body>
</html>
